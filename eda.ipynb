{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import tweepy\n",
    "import ssl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openai\n",
    "pd.set_option(\"display.max_rows\", 100000)\n",
    "pd.set_option(\"display.max_columns\", 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "# Oauth keys\n",
    "consumer_key = \"gGRiYPUuuhoITbhGklzIO6ZvF\"\n",
    "consumer_secret = \"jgEejdxKGqEaa8MnP02rzgCap6nbb34PknIcVIyLXfiTuDxYG6\"\n",
    "access_token = \"410230715-kA0BPkYbnNPNHpiHpFRf5IB8ujjVGsatjvOkZJAN\"\n",
    "access_token_secret = \"AzBSeCFs8zUFgR2eFyoNHvaJPHwrSiXjRRTsd45ieLBY0\"\n",
    "# Authentication with Twitter\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth ,wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24783, 7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/Users/ikuti/Desktop/ikuti/Other/hate-speech-and-offensive-language/data/labeled_data.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'MrDtAFC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweets = []\n",
    "tw = api.user_timeline(screen_name=name, \n",
    "                           # 200 is the maximum allowed count\n",
    "                           count=200,\n",
    "                           include_rts = False,\n",
    "                           # Necessary to keep full_text \n",
    "                           # otherwise only the first 140 words are extracted\n",
    "                           tweet_mode = 'extended'\n",
    "                           )\n",
    "for info in tw:\n",
    "     #print(\"ID: {}\".format(info.id))\n",
    "     #print(info.created_at)\n",
    "     test_tweets.append([info.created_at,info.full_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports for model train\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## look at more data\n",
    "more_data = pd.read_csv('/Users/ikuti/Desktop/ikuti/Other/hate-speech-and-offensive-language/data/more_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_offensive</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69244</th>\n",
       "      <td>0</td>\n",
       "      <td>adn Canwest shareholders</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       is_offensive                      text\n",
       "69244             0  adn Canwest shareholders"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "more_data.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_data.dropna( inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##clean text\n",
    "def clean_tweet_v2(df):\n",
    "    df['text'] = df.text.str.replace('!|RT','')\n",
    "    result = []\n",
    "    for i in df[['text']].itertuples():\n",
    "        a_ = i[1].split()\n",
    "        as_ = [x.strip() for x in a_ if '@' not in x]\n",
    "        asp_ = [x for x in as_ if 'http' not in x]\n",
    "        result.append(' '.join([x for x in asp_ if '&#' not in x]))\n",
    "    df['clean_tweets'] = result\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_data = clean_tweet_v2(more_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_offensive</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>112382</th>\n",
       "      <td>1</td>\n",
       "      <td>I think a lot of bitches don't smile in their ...</td>\n",
       "      <td>I think a lot of bitches don't smile in their ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        is_offensive                                               text  \\\n",
       "112382             1  I think a lot of bitches don't smile in their ...   \n",
       "\n",
       "                                             clean_tweets  \n",
       "112382  I think a lot of bitches don't smile in their ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "more_data.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data for training\n",
    "x_train,x_test,y_train,y_test = train_test_split(more_data.clean_tweets,more_data.is_offensive,test_size = 0.2 , random_state = 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## transform text using count vectorizer\n",
    "cv = CountVectorizer()\n",
    "cv.fit(more_data.clean_tweets)\n",
    "X_train = cv.transform(x_train)\n",
    "X_test = cv.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    }
   ],
   "source": [
    "### transform data for xgb\n",
    "D_train = xgb.DMatrix(X_train, label=y_train)\n",
    "D_test = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'eta': 0.1, \n",
    "    'max_depth': 5,  \n",
    "    'objective': 'multi:softprob',  \n",
    "    'num_class': 2} \n",
    "\n",
    "steps = 15  # The number of training iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.train(param, D_train, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 0.9440362696639357\n",
      "Recall = 0.7725263520850669\n",
      "Accuracy = 0.9086520206129645\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "\n",
    "preds = model.predict(D_test)\n",
    "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "\n",
    "print(\"Precision = {}\".format(precision_score(y_test, best_preds, average='macro')))\n",
    "print(\"Recall = {}\".format(recall_score(y_test, best_preds, average='macro')))\n",
    "print(\"Accuracy = {}\".format(accuracy_score(y_test, best_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Naive bayes \n",
    "nb = MultinomialNB(alpha = 0.25)\n",
    "nb.fit(X_train , y_train)\n",
    "pred = nb.predict(X_test)\n",
    "score = accuracy_score(pred,y_test) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.64090046107947"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=0, splitter='best')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## decision tree with\n",
    "dt_more = DecisionTreeClassifier(random_state = 0)\n",
    "dt_more.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dt_m = dt_more.predict(X_test)\n",
    "score_dt_m = accuracy_score(pred_dt_m , y_test) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 0.9174041216428841\n",
      "Recall = 0.9045670483104844\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision = {}\".format(precision_score(y_test, pred_dt_m, average='macro')))\n",
    "print(\"Recall = {}\".format(recall_score(y_test, pred_dt_m, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.4019528071603"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_dt_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28654,  1180],\n",
       "       [  884,  6152]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(pred_dt_m , y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97     29538\n",
      "           1       0.87      0.84      0.86      7332\n",
      "\n",
      "    accuracy                           0.94     36870\n",
      "   macro avg       0.92      0.90      0.91     36870\n",
      "weighted avg       0.94      0.94      0.94     36870\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test , pred_dt_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##save model\n",
    "'''\n",
    "import pickle\n",
    "\n",
    "filename = 'decision_tree.pkl'\n",
    "with open(filename , 'wb') as file:\n",
    "    pickle.dump(dt_more, file)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to predict\n",
    "def get_prediction(text , model , cv):\n",
    "    ##text in list\n",
    "    text = cv.transform([text])\n",
    "    pred = model.predict(text)\n",
    "    if pred[0] == 1:\n",
    "        return 'Offensive'\n",
    "    else:\n",
    "        return 'Not Offensive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Not Offensive'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prediction('you are so nice' , dt , cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GUI testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = tk.Tk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pickle.load(open('decision_tree.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df , test_df = train_test_split(more_data,test_size = 0.2 , random_state = 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = Tokenizer(num_words = None , char_level = False)\n",
    "token.fit_on_texts(more_data.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq = pad_sequences(token.texts_to_sequences(train_df.text),maxlen = 50)\n",
    "test_seq = pad_sequences(token.texts_to_sequences(test_df.text),maxlen = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lab = np.array(train_df.is_offensive) \n",
    "test_lab = np.array(test_df.is_offensive) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 50, 128)           27719552  \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 6401      \n",
      "=================================================================\n",
      "Total params: 27,725,953\n",
      "Trainable params: 27,725,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "147480/147480 [==============================] - 514s 3ms/step - loss: 0.4692 - accuracy: 0.7995\n",
      "Epoch 2/5\n",
      "147480/147480 [==============================] - 506s 3ms/step - loss: 0.4194 - accuracy: 0.8013\n",
      "Epoch 3/5\n",
      "147480/147480 [==============================] - 485s 3ms/step - loss: 0.3744 - accuracy: 0.8362\n",
      "Epoch 4/5\n",
      "147480/147480 [==============================] - 486s 3ms/step - loss: 0.3240 - accuracy: 0.8733\n",
      "Epoch 5/5\n",
      "147480/147480 [==============================] - 488s 3ms/step - loss: 0.2832 - accuracy: 0.8954\n",
      "36870/36870 [==============================] - 1s 20us/step\n",
      "89.89 <keras.engine.sequential.Sequential object at 0x7fd53501c390>\n"
     ]
    }
   ],
   "source": [
    "emb = Embedding(len(token.word_index)+1,128,input_length = 50)\n",
    "dense = Dense(1,activation = 'sigmoid')\n",
    "model = Sequential()\n",
    "model.add(emb)\n",
    "model.add(Flatten())\n",
    "model.add(dense)\n",
    "model.compile(optimizer = 'sgd',loss = 'binary_crossentropy',metrics = ['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(train_seq,train_lab,epochs = 5)\n",
    "loss,accuracy = model.evaluate(test_seq,test_lab)\n",
    "print(round(accuracy * 100,2),model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['I hope you die']\n",
    "name_token = pad_sequences(token.texts_to_sequences(names),maxlen = 50)\n",
    "pred = model.predict_classes(name_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0]], dtype=int32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPEN AI TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = \"sk-AxNaQumDedma7T3Kr98vS0UZ83OP037TMqSvBbQD\"\n",
    "response = openai.Completion.create(engine=\"davinci\", prompt=\"Most people think machines will take their jobs\", max_tokens=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" and make them worse. Contrary to popular opinion, the next generation may see that as a good thing. I wrote about the changing paradigm in Ask' is becoming part of our culture -- and we're going to learn that 'the network is stronger than\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
